texto <- 'Y, viéndole don Quijote de aquella manera, con muestras de tanta tristeza, le dijo: Sábete, Sancho, que no es un hombre más que otro si no hace más que otro. Todas estas borrascas que nos suceden son señales de que presto ha de serenar el tiempo y han de sucedernos bien las cosas; porque no es posible que el mal ni el bien sean durables, y de aquí se sigue que, habiendo durado mucho el mal, el bien está ya cerca. Así que, no debes congojarte por las desgracias que a mí me suceden, pues a ti no te cabe parte dellas. Y, viéndole don Quijote de aquella manera, con muestras de tanta tristeza, le dijo: Sábete, Sancho, que no es un hombre más que otro si no hace más que otro. Todas estas borrascas que nos suceden son señales de que presto ha de serenar el tiempo y han de sucedernos bien las cosas; porque no es posible que el mal ni el bien sean durables, y de aquí se sigue que, habiendo durado mucho el mal, el bien está ya cerca. Así que, no debes congojarte por las desgracias que a mí me suceden, pues a ti no te cabe parte dellas. Y, viéndole don Quijote de aquella manera, con muestras de tanta tristeza, le dijo: Sábete, Sancho, que no es un hombre más que otro si no hace más que otro. Todas estas borrascas que nos suceden son señales de que presto ha de serenar el tiempo y han de sucedernos bien las cosas; porque no es posible que el mal ni el bien sean durables, y de aquí se sigue que, habiendo durado mucho el mal, el bien está ya cerca. Así que, no debes congojarte por las desgracias que a mí me suceden, pues a ti no te cabe parte dellas. Y, viéndole don Quijote de aquella manera, con muestras de tanta tristeza, le dijo: Sábete, Sancho, que no es un hombre más que otro si no hace más que otro. Todas estas borrascas que nos suceden son señales de que presto ha de serenar el tiempo y han de sucedernos bien las cosas; porque no es posible que el mal ni el bien sean durables, y de aquí se sigue que, habiendo durado mucho el mal, el bien está ya cerca. Así que, no debes congojarte por las desgracias que a mí me suceden, pues a ti no te cabe parte dellas.Y, viéndole don Quijote de aquella manera, con muestras de tanta tristeza, le dijo: Sábete, Sancho, que no es un hombre más que otro si no hace más que otro. Todas estas borrascas que nos suceden son señales de que presto ha de serenar el tiempo y han de sucedernos bien las cosas; porque no es posible que el mal ni el bien sean durables, y de aquí se sigue que, habiendo durado mucho el mal, el bien está ya cerca.'
texto
text <- read.delim('./demo.txt')
text <- read.delim("./demo.txt")
text <- read.delim("demo.txt")
install.packages("readr")
library(readr)
text <- read_file("./demo.txt")
text
text <- read_file_raw("./demo.txt")
text
text <- read_file("./demo.txt")
text
ll
text <- readLines("./demo.txt", encoding = "UTF-8")
text
text <- readLines("./demo.txt", encoding = "latin1")
text
toupper("e")
toupper("È")
toupper("é")
iconv("Quéèëééé", from="latin1", to ="ASCII//TRANSLIT")
# 1. Sentence split
phrases <- strsplit(text, split = ".")
phrases
View(phrases)
phrases <- strsplit(text, split = "[.]")
phrases
View(phrases)
text <- readLines("./demo.txt", encoding = "latin1")
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
phrases
text
# 1. Sentence split
phrases <- strsplit(text, split = "[.]\W+")
phrases
# 1. Sentence split
phrases <- strsplit(text, split = "[.]\W*")
phrases
text <- gsub("[.][\s\r+]+", ".", readLines("./demo.txt", encoding = "latin1"))
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
text <- gsub("[.][\\s\\r+]+", ".", readLines("./demo.txt", encoding = "latin1"))
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
text <- sub("[.][\\s\\r+]+", ".", readLines("./demo.txt", encoding = "latin1"))
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
text <- readLines("./demo.txt", encoding = "latin1")
text <- readLines("./demo.txt", encoding = "latin1")
text
text_u <- sub("[.][\\s\\r+]+", ".", text)
text_u
# 1. Sentence split
phrases <- strsplit(text_u, split = "[.]")
phrases
text_u
text
text <- gsub("[.][\\s\\r+]+", ".", readLines("./demo.txt", encoding = "latin1"))
text
text <- gsub("[.][\\s\\r]+", ".", readLines("./demo.txt", encoding = "latin1"))
text
text <- gsub("[.][\\s\\r+]", ".", readLines("./demo.txt", encoding = "latin1"))
text
text <- readLines("./demo.txt", encoding = "latin1")
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text_u, split = "[.]")
phrases
text <- readLines("./demo.txt", encoding = "latin1")
# 1. Sentence split
phrases <- strsplit(text_u, split = "[.]")
###############################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
phrases
text <- readLines("./demo.txt", encoding = "latin1")
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
phrases
install.packages("snowball")
install.packages("corpus")
library(corpus)
phrases[1]
phrases[[1]]
View(phrases)
phrases[[1]][1]
text_tokens(phrases[[1]][1], stemmer = "es")
text_tokens(phrases[[1]][1], stemmer = "es")
phrases[[1]][1]
text_tokens(iconv(phrases[[1]][1], from = "latin1", to = "ASCII//TRANSLIT"), stemmer = "es")
phrases[[1]][1]
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# Lemmatization
tmp <- tempfile()
download.file("http://www.lexiconista.com/Datasets/lemmatization-es.zip", tmp)
con <- unz(tmp, "lemmatization-es.txt", encoding = "latin1")
con
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# Lemmatization
tmp <- tempfile()
download.file("http://www.lexiconista.com/Datasets/lemmatization-es.zip", tmp)
con <- unz(tmp, "lemmatization-es.txt", encoding = "latin1")
tab <- read.delim(con, header = FALSE, stringsAsFactors = FALSE)
tab
tmp <- tempfile()
download.file("http://www.lexiconista.com/Datasets/lemmatization-es.zip", tmp)
con <- unz(tmp, "lemmatization-es.txt", encoding = "UTF-8")
tab <- read.delim(con, header = FALSE, stringsAsFactors = FALSE)
tab
con <- unz(tmp, "lemmatization-es.txt", encoding = "latin1")
tab <- read.delim(con, header = FALSE, stringsAsFactors = FALSE)
tab
text
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# Lemmatization
dictionary <- read.delim("./lemmatization-es.txt", encoding = "latin1", header = FALSE, stringsAsFactors = FALSE)
dictionary
dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
dictionary
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# Lemmatization
dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(dictionary) <- c("stem", "term")
head(dictionary
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# Lemmatization
dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(dictionary) <- c("stem", "term")
head(dictionary)
dictionary
print(text_tokens(c("run", "ran", "running"), stemmer = "en"))
print(text_tokens(c("operando", "ópera", "operáis"), stemmer = "es"))
p_dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(p_dictionary) <- c("stem", "term")
stems_parser <- new_stemmer(dictionary$term, dictionary$stem)
for (term in phrases) {
print(text_tokens(term, stemmer = stems_parser))
}
p_dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(p_dictionary) <- c("lemma", "term")
lemmas_parser <- new_stemmer(dictionary$term, dictionary$lemma)
for (term in phrases) {
print(text_tokens(term, stemmer = lemmas_parser))
}
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# 2.1. Lemmatization
p_dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(p_dictionary) <- c("lemma", "term")
head(p_dictionary)
p_dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(p_dictionary) <- c("lemma", "term")
head(p_dictionary)
lemmas_parser <- new_stemmer(p_dictionary$term, p_dictionary$lemma)
for (term in phrases) {
print(text_tokens(term, stemmer = lemmas_parser))
}
for (term in phrases) {
#stemmed_text[[i]] <- text_tokens(term, stemmer = lemmas_parser)
print(typeof(text_tokens(term, stemmer = lemmas_parser)))
}
stemmed_text <- list()
i <- 1
for (term in phrases) {
stemmed_text[[i]] <- paste(unlist(text_tokens(term, stemmer = lemmas_parser)), collapse = " ")
print(typeof(text_tokens(term, stemmer = lemmas_parser)))
i <- i + 1
}
stemmed_text
# 2.2. Stemming
stemmed_text <- list()
i <- 1
for (term in phrases) {
print(term)
stemmed_text[[i]] <- paste(unlist(text_tokens(term, stemmer = lemmas_parser)), collapse = " ")
print(typeof(text_tokens(term, stemmer = lemmas_parser)))
i <- i + 1
}
stemmed_text
stemmed_text <- list()
i <- 1
for (term in phrases) {
print(term)
print("-----")
stemmed_text[[i]] <- paste(unlist(text_tokens(term, stemmer = lemmas_parser)), collapse = " ")
print(typeof(text_tokens(term, stemmer = lemmas_parser)))
i <- i + 1
}
stemmed_text
View(phrases)
stemmed_text <- list()
i <- 1
for (term in phrases[[1]]) {
print(term)
print("-----")
stemmed_text[[i]] <- paste(unlist(text_tokens(term, stemmer = lemmas_parser)), collapse = " ")
print(typeof(text_tokens(term, stemmer = lemmas_parser)))
i <- i + 1
}
stemmed_text <- list()
i <- 1
for (term in phrases[[1]]) {
stemmed_text[[i]] <- paste(unlist(text_tokens(term, stemmer = lemmas_parser)), collapse = " ")
print(typeof(text_tokens(term, stemmer = lemmas_parser)))
i <- i + 1
}
stemmed_text
lemmatized_text <- list()
i <- 1
for (phrase in phrases[[1]]) {
lemmatized_text[i] <- paste(unlist(text_tokens(phrase, stemmer = lemmas_parser)), collapse = " ")
print(typeof(text_tokens(phrase, stemmer = lemmas_parser)))
i <- i + 1
}
lemmatized_text <- list()
i <- 1
for (phrase in phrases[[1]]) {
lemmatized_text[i] <- paste(unlist(text_tokens(phrase, stemmer = lemmas_parser)), collapse = " ")
i <- i + 1
}
lemmatized_text
for (phrase in lemmatized_text) {
print(phrase)
print("-----------")
}
# 2.2. Stemming
stemmed_text <- list()
i <- 1
for (phrase in lemmatized_text) {
stemmed_text[i] <- paste(unlist(text_tokens(phrase, stemmer = "es")), collapse = " ")
}
stemmed_text
text <- readLines("./demo.txt", encoding = "latin1")
###################################################################################
############################### 1. Data preparation ###############################
###################################################################################
# 1. Sentence split
phrases <- strsplit(text, split = "[.]")
phrases
# 2. Feature selection
text_tokens(iconv(phrases[[1]][1], from = "latin1", to = "ASCII//TRANSLIT"), stemmer = "es")
phrases[[1]][1]
# https://cran.r-project.org/web/packages/corpus/vignettes/stemmer.html
# 2.1. Lemmatization
p_dictionary <- read.delim("./lemmatization-es.txt", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
names(p_dictionary) <- c("lemma", "term")
head(p_dictionary)
lemmas_parser <- new_stemmer(p_dictionary$term, p_dictionary$lemma)
lemmatized_text <- list()
i <- 1
for (phrase in phrases[[1]]) {
lemmatized_text[i] <- paste(unlist(text_tokens(phrase, stemmer = lemmas_parser)), collapse = " ")
i <- i + 1
}
# 2.2. Stemming
stemmed_text <- list()
i <- 1
for (phrase in lemmatized_text) {
stemmed_text[i] <- paste(unlist(text_tokens(phrase, stemmer = "es")), collapse = " ")
i <- i + 1
}
stemmed_text
View(lemmatized_text)
View(stemmed_text)
View(phrases)
